---
title: "Data Munging"
author: "James B. Elsner"
date: September 11, 2018
output: 
  html_document:
    keep_md: true
---

"**Science is the belief in the ignorance of experts.**"---Richard Feynman

After today you will know how to manipulate data frames. 

## Median

Recall from last week that the mean is a statistic that provides a model for our data. Typically there are more data values near the mean than far from it. The mean is often near the middle value of a set of observations.

The median is a statistic defined as the "middle" value. Given a set of data values arranged from lowest value to highest value, the median is the middle value.

For example, consider a set of seven data values. Here the seven values are generated randomly but reproducibly. The `set.seed()` function will guarantee the everyone using the seed number (here 3042) will get the same set of values.
```{r}
set.seed(3043)
data <- rnorm(7)
sort(data)
```

The middle value is the fourth value from the left in the ordered list of data values.
```{r}
median(data)
```

With an odd number of data values, the median is the middle one; with an even number of data values, the median is the average of the two middle values.

```{r}
data <- rnorm(8)
sort(data)
median(data)
```

We can check to see this is true no matter what the values are
```{r}
data <- rnorm(8)
data_sorted <- sort(data)
median(data) == mean(c(data_sorted[4], data_sorted[5]))
```

The median value as a statistic representing the middle of a set of data values is said to be resistant to outliers.

Consider the wealth (in 1000s of $) of five bar patrons.
```{r}
bar <- c(50, 60, 100, 75, 200)
```

Now consider the same bar and patrons after a multimillionaire walks in.
```{r}
bar_with_mm <- c(bar, 50000)
```

```{r}
mean(bar)
mean(bar_with_mm)
median(bar)
median(bar_with_mm)
```

The difference in the mean wealth with and without the millionaire present is substantial while the difference in medians is small. Statistics that are not greatly influenced be a few values far from the bulk of the data are called resistant statistics.

The median value divides the data set into the top 50% of the data values and the bottom 50% of the data values.

The `cfb` (**UsingR**) data set contains data from the Survey of Consumer Finances conducted by the U.S. Federal Reserve Board (in 2001). Some of the income values are much higher than the bulk of the data. This tendency is common in income distributions (and it's getting worse). A few people tend to accumulate enormous wealth.

Make the functions (and data) from the package available then assign to `income` the column `INCOME` in the `cfb` data frame. Then compute the mean and median.
```{r}
library("UsingR")
income <- cfb$INCOME
mean(income)
median(income)
```

The mean is larger than the median. This indicates there are more large values than small values. 

This can be seen using a histogram plot. A histogram displays the frequency of the values using intervals that divide the values into equal bins. This is done with the `hist()` function. Here we specify the number of intervals with the `breaks = ` argument.
```{r}
hist(income, 
     breaks = 25)
```

The distribution is right skewed. It has a long right tail.

Note: Many packages have built-in datasets. To see what datasets are available in a package, type
```{r, eval=FALSE}
data(package = "UsingR")
```

## Spread

One measure of the spread of data values is the range. The range is given by the minimum and maximum value (or by the difference between the minimum and maximum).
```{r}
range(income)
diff(range(income))
```

We can define spread in terms of deviations from the center value. As we've seen the sum of the squared deviations from the center divided by sample length minus one is the sample variance.
```{r}
var(income)
sqrt(var(income))
sd(income)
```

To illustrate consider two sets of test scores.
```{r}
ts1 <- c(80, 85, 75, 77, 87, 82, 88)
ts2 <- c(100, 90, 50, 57, 82, 100, 86)
```

Some test score statistics are
```{r}
mean(ts1)
mean(ts2)
var(ts1)
var(ts2)
```

## Quantiles

Quantiles cut a set of ordered data values into equal-sized bins. The ordering comes from rearranging the data from lowest to highest. The first, or lower, quartile corresponding to the .25 quantile (25th percentile), indicates that 25% of the values are less than this quantile number. The third quartile corresponding to the .75 quantile (75th percentile), indicates that 75% of the values are less than this quantile number.

The `quantile()` function calculates sample quantiles on a vector of data. For example, consider Florida precipitation for the month of June. Source: Monthly climate series. http://www.esrl.noaa.gov/psd/data/timeseries/

Get monthly precipitation values for the state back to the year 1895. Copy/paste into a text editor (notepad) then import into R using the `read.table()` function. Add column names.

Here I did it for Florida and posted the file on my website. Missing values are coded as -9.900.
```{r}
loc <- "http://myweb.fsu.edu/jelsner/temp/data/FLprecip.txt"
FLp <- read.table(loc, 
                  na.string = "-9.900", 
                  header = TRUE)
```



Apply the `sort()` function on the June values (column indicated by the label Jun).
```{r}
sort(FLp$Jun)
```

Note the use of the dollar sign to indicate the column in the data frame.

Next find the 25th and 50th percentile values.
```{r}
quantile(FLp$Jun, 
         probs = c(.25, .5))
```

Of the `r I(length(FLp$Jun))` monthly precipitation values, 25% of them are less than `r round(quantile(FLp$Jun,probs=.25),2)` inches, 50% are less than `r I(round(quantile(FLp$Jun,probs=.5),2))` inches.  Thus there are an equal number of years with June precipitation between `r I(round(quantile(FLp$Jun,probs=.25),2))` and `r I(round(quantile(FLp$Jun,probs=.5),2))` inches.

The third quartile value corresponding to the .75 quantile (75th percentile) indicates that 75% of the data have a value less than this. The difference between the first and third quartile values is called the interquartile range (IQR). Fifty percent of all values lie within the IQR. The IQR is obtained using the `IQR()` function.

Another example: Consider the set of North Atlantic Oscillation (NAO) index values for the month of June from the period 1851--2010.  The NAO is a variation in the climate over the North Atlantic Ocean featuring fluctuations in the difference of atmospheric pressure at sea level between the Iceland and the Azores. 

The index is computed as the difference in standardized sea-level pressures. The standardization is done by subtracting the mean and dividing by the standard deviation. The units on the index is standard deviation.

First import the data consisting of monthly NAO values, then list the column names and the first few lines of the data frame.
```{r}
loc <- "http://myweb.fsu.edu/jelsner/temp/data/NAO.txt"
NAO <- read.table(loc, 
                  header = TRUE)
head(NAO)
```

Determine the 5th and 95th percentile values for the month of June.
```{r}
quantile(NAO$Jun, 
         prob = c(.05, .95))
```

## Data frames

The function `read.table()` (and its variants) return data frames. `H` is a data frame.  

We import data directly from the web by specifying the URL instead of the local file name. Of course this requires that we are connected to the internet.
```{r}
loc <- "http://myweb.fsu.edu/jelsner/temp/data/US.txt"
H <- read.table(file = loc, 
                header = TRUE)
```

A data frame is like a spreadsheet. Values are arranged in rows and columns. Rows are the cases (observations) and columns are the variables. The `dim()` function gives the size of the data frame (number of rows and number of columns).
```{r}
dim(H)
```

There are `r I(dim(H)[1])` rows and `r I(dim(H)[2])` columns in the data frame.

Note: Here we use inline code. Open with a single grave accent followed by the letter r and close with a grave accent.

To list the first six lines of the data object, type
```{r}
head(H)
```

The columns include year, number of hurricanes, number of major hurricanes, number of Gulf coast hurricanes, number of Florida hurricanes, and number of East coast hurricanes in order. Column names are printed as well.  

The last six lines of the data frame are listed similarly using the `tail()` function. The number of lines listed is changed using the argument `n =`.
```{r}
tail(H, n = 3)
```

The number of years in the record is assigned to the object `nY` and the annual average number of hurricanes (rate) is assigned to the object `rate`.
```{r}
nY <- length(H$All)
rate <- mean(H$All)
```

By typing the names of the saved objects, the values are printed.
```{r}
nY
rate
```

Thus over the `r I(nY)` years of data the average number of hurricanes per year is `r I(round(rate, digits = 2))`.

If we want to change the names of the columns in the data frame, type
```{r}
names(H)[4] <- "GC"
names(H)
```

This changes the 4th column name from G to GC. Note that this change occurs to the data frame in R and not to your original data file.

Most of our work with R will involve data frames. A data frame is a tabular (rectangular) data structure, which means it has rows and columns.  It is like a matrix with column names. Actually it is a list:

* Elements of the list are vectors.
* Vectors are the columns in the data frame.
* Vectors must all have the same length; in other words, all columns must have the same height.
* Equal-height columns gives it a rectangular shape.
* Columns must have names.

To print the first column of values (the years) you can type:
```{r, eval=FALSE}
H[1]
```

Or
```{r, eval=FALSE}
H[, 1]
H[[1]]
H$Year
```

Data frames have two indices indicating the rows and columns in that order.
```{r}
H[10, 4]
```

* To a statistician a data frame is a table of observations. Each row contains one observation. Each observation must contain the same variables. These variables are called columns, and you can refer to them by name.  You can also refer to the contents by row number and column number, just as with a matrix.

* To an Excel user a data frame is like a worksheet (or a range within a worksheet). A data frame is more restrictive, however, in that each column has a type.

* To an R programmer a data frame is a data structure, part matrix and part list.  A column can contain numbers, character strings, or factors but not a mix of them.  You can index the data frame just like you index a matrix. The data frame is also a list, where the list elements are the columns, so you can access columns by using list operators.

## Example: Florida precipitation by month

Plot a time series graph of January precipitation in Florida.
```{r}
library(ggplot2)
ggplot(FLp, aes(x = Year, y = Jan)) +
  geom_line() +
  ylab("January Precipitation in Florida (in)")
```

## The summary method

The `summary()` function provides summary statistics for each column in your data frame. The statistics include output the mean, median, minimum, maximum, along with the first quartile and third quartile values.
```{r}
summary(FLp)
```

Columns with missing values get a row output from the `summary()` function indicating the number of them (NA's).

### Creating a data frame

Consider ice volume (1000 km$^3$) measurements from the arctic from 2002 to 2012. The measurements are taken on January 1st each year and are available from http://psc.apl.washington.edu/wordpress/research/projects/arctic-sea-ice-volume-anomaly/data/
```{r}
Volume <- c(20.233, 19.659, 18.597, 18.948, 17.820, 
           16.736, 16.648, 17.068, 15.916, 14.455, 
           14.569)
```

The object `Volume` is a vector. Since the data values are ordered (earliest to latest) we can create another vector containing the sequence of corresponding years. Then, the function `data.frame()` creates the data frame object from the two vectors.
```{r}
Year <- 2002:2012
Ice.df <- data.frame(Year, Volume)
head(Ice.df)
```

The names of the columns are the names of the corresponding vectors unless otherwise specified (e.g., `yr = Year`). 

Recall we use the subset operator `[]` to extract values from the data frame. For example, what year had the minimum volume of ice?
```{r}
which.min(Ice.df$Volume)
Ice.df[10, ]
Ice.df$Year[which.min(Ice.df$Volume)]
```

To change a single vector object to a data frame use the function `as.data.frame()`. For example, let `counts` be a vector of random integers. We generate a sample of size 100 with values from a Poisson distribution having a rate of 1.69. 
```{r}
counts <- rpois(100, lambda = 1.69)
head(counts)
H <- as.data.frame(counts)
head(H)
```

Similarly for the ice volume data you can use the function `cbind()` [combine columns] within the function `as.data.frame()`.
```{r}
as.data.frame(cbind(Year, Volume))
```

## Grammar for data

The **dplyr** package has functions ('verbs') that perform common data operations on data frames. Filtering for rows, selecting specific columns, re-ordering rows, adding new columns, and summarizing data. The functions make working with a data frame easier than the **base** functions (`split()`, `subset()`, `lapply()`, etc).

```{r eval=FALSE}
install.packages("dplyr")
```
```{r}
library(dplyr)
```

Lets return to the `airquality` data. The data frame is in the **datasets** package and contains daily air quality measurements in New York City from May to September 1973. Ozone concentration in ppb, solar radiation in langleys, wind speed in mph, temperature in F, month and day of month.
```{r}
head(airquality)
dim(airquality)
```

There are 153 rows and 6 columns. The rows are called observations and the columns are called variables. This is typically the way you store data collected in a spreadsheet.

The notes below follow: http://genomicsclass.github.io/book/pages/dplyr_tutorial.html

The important **dplyr** verbs are

Verb        | Description
-----------:|:-----------
`select()`    | selects columns; pick variables by their names
`filter()`    | filters rows; pick observations by their values
`arrange()`   | re-orders the rows
`mutate()`    | creates new columns; create new variables with functions of existing variables
`summarize()` | summarizes values; collapse many values down to a single summary
`group_by()`  | allows operations to be grouped

### Select

The function `select()` picks variables by name.

For example, create a new data frame containing only the month, day, and temperature columns from the `airquality` data frame.
```{r}
df <- airquality %>%
      select(Month, Day, Temp)
head(df)
```

The result is a data frame `df` that contains only the columns listed in the `select()` function.

The operator `%>%` is called the 'pipe' and your read it as 'then'. For example, we read the above code as "Take the data frame `airquality` THEN (`%>%`) select the columns `Month`, `Day`, and `Temp`."

All verbs work the same way: The first argument is a data frame and this argument is passed into the function with the pipe operator; The subsequent arguments describe what to do with the data frame, using the variable names; The result is always a new data frame

Select all the columns *except*  solar radiation.
```{r}
df <- airquality %>% 
  select(-Solar.R)
head(df)
```

To select a range of columns by names, use the colon (`:`) operator.
```{r}
df <- airquality %>%
   select(Wind:Day)
head(df)
```

To select all columns that contain the character "n", use the function `contains()`.
```{r}
df <- airquality %>%
  select(contains("n"))
head(df)
```

Additional options to select columns based on specific criteria include.

Criteria       | Description
--------------:|:-----------
`ends_with()`    | select columns that end with character string
`starts_with()`  | select columns that start with a character string
`matches()`      | select columns that match a regular expression
`one_of()`       | select column names that are from a group of names

### Filter

The function `filter()` is used to subset observations based on specific values.

Create a new data frame with June values of air quality measurements.
```{r}
df <- airquality %>%
  filter(Month == 6)
head(df)
```

Filter the rows for temperature at least 80 F and winds less than 5 mph.
```{r}
df <- airquality %>% 
  filter(Temp >= 80 & Wind < 5)
head(df)
```

Multiple arguments to `filter()` are combined with "and": every expression must be true in order for a row to be included in the output. 

For other types of combinations, we need to use Boolean operators: `&` is "and", `|` is "or", and `!` is "not".

The following code finds all observations taken in May and September.
```{r}
df <- airquality %>% 
  filter(Month == 5 | Month == 9)
```

Note: We can't write `filter(Month == 5 | 9)` although `filter(Month %in% c(5, 9))` works. 

We use the operators (e.g., `>`, `<`, `>=`, `<=`, `!=`, `|` (or)) to create logical tests for filtering.

NOTE: A common mistake is to use `=` instead of `==` when testing for equality.

The output from the function (or object) to the left of the pipe operator is assumed as the first argument of the function to the right of the pipe. 

The `%>%` operator works by taking the output from the function (or object) immediately before the pipe as the first arugment to the function immediately after the pipe.

For example: take the data frame `airquality` THEN select the columns `Temp`, `Day`, and `Month`, THEN list the first six rows is written as:
```{r}
airquality %>% 
  select(Temp, Day, Month) %>% 
  head()
```

Suppose we want to create a new data frame that is a filtered and subsetted version of the original one. For example, suppose we only want to work with the ozone, wind and temperature data from August and September when the winds are light.
```{r}
df = airquality %>%
  filter(Month == 8 | Month == 9 & Wind < 5) %>%
  select(Month, Day, Ozone, Wind, Temp)
```

"Assign to `df` the `airquality` data frame filtered by month and wind speed and selecting only the columns labeled `Month`, `Day`, `Ozone`, `Wind`, and `Temp`"
  
### Arrange

To arrange (or re-order) rows by a particular column such as solar radiation.
```{r}
airquality %>%
  arrange(desc(Solar.R)) %>%
  head()
```

Make a new data frame by selecting three columns (`Solar.R`, `Wind`, and `Temp`) from `airquality`, arrange the rows by temperature and then arrange by solar radiation.
```{r}
df = airquality %>%
  select(Solar.R, Wind, Temp) %>%
  arrange(Temp, Solar.R)
head(df)
```

The arrangement is done from lowest to highest values first by temperature and then by radiation.

Same as above, except here you filter for temperatures exceeding 90 F.
```{r}
airquality %>%
  select(Solar.R, Wind, Temp) %>%
  arrange(Temp, Solar.R) %>%
  filter(Temp > 90)
```

Same as above, except here you arrange by descending temperature with the `desc()` function.
```{r}
airquality %>%
  select(Solar.R, Wind, Temp) %>%
  arrange(desc(Temp), Solar.R) %>%
  filter(Temp > 90)
```

The second variable breaks the ties from the first variable.

### Mutate

The `mutate()` function adds new columns to the data frame. For example, create a new column called `TempC` which is the temperature in Celcius. Also create a column called `WindMS` which is the wind speed in meters per second.
```{r}
airquality %>%
  mutate(TempC = (Temp - 32) * 5/9,
         WindMS = Wind * .44704) %>%
  head()
```

On days when the temperature is below 60 F compute the apparent temperature based on wind chill and arrange from coldest to warmest apparent temperature.
```{r}
airquality %>%
  filter(Temp < 60) %>%
  mutate(TempAp = 35.74 + .6215 * Temp - 35.75 * Wind^.16 + .4275 * Temp * Wind^.16) %>%
  arrange(TempAp)
```

### Summarize

The `summarize()` (or `summarise()`) function creates summary statistics for a given column in the data frame. To compute the average wind speed during July type
```{r}
airquality %>%
  filter(Month == 7) %>%
  summarize(Wavg = mean(Wind))
```

We've looked at several summary functions already including `sum()`, `sd()`, `min()`, `max()`, `var()`, `range()`, `median()`. Others include

Summary function  | Description
-----------------:|:-----------
`n()`             | Length of the column
`first()`         | First value of the column
`last()`          | Last value of the column
`n_distinct()`    | Number of distinct values

Find the maximum and median wind speed and maximum ozone concentration values during the month of May. Also determine the number of days during Mays.
```{r}
airquality %>%
  filter(Month == 5) %>%
  summarize(Wmax = max(Wind),
            Wmed = median(Wind),
            OzoneMax = max(Ozone, na.rm = TRUE),
            NumDays = n())
```

### Grouping

What if we want to apply the above summary separately for each month? Use the `group_by()` function. We split the data frame by some variable (e.g., `Month`), apply a function to the individual data frames, and then combine the output.

Find the highest ozone concentration for each month.
```{r}
airquality %>%
  group_by(Month) %>%
  summarize(OzoneMax =  max(Ozone, na.rm = TRUE),
            NumDays = n())
```

Find the average ozone concentration when temperatures are above and below 70 F.
```{r}
airquality %>%
  group_by(Temp >= 70) %>%
  summarize(OzoneAvg =  mean(Ozone, na.rm = TRUE),
            NumDays = n())
```

On average ozone concentrations are higher on warm days (Temp >= 70 F) days. That is to say mean ozone concentration depends on temperature, where the word 'depends' implies statistical dependency.

The mean is a model for the data. The statistical dependency of the mean implies that a model for ozone concentration will likely be improved by including temperature as an explanatory variable.

### A grammar

As noted the syntax of the verb functions are all the same:

* The first argument is a data frame.
* The subsequent arguments describe what to do with the data frame. Notice that you can refer to columns in the data frame directly without using $.
* The result is a new data frame

These properties make it easy to chain together many simple steps to achieve a complex result.

The five functions provide the basis of a grammar for data. At the most basic level, you can only alter a data frame in five useful ways: you can reorder the rows (`arrange()`), pick observations and variables of interest (`filter()` and `select()`), add new variables that are functions of existing variables (`mutate()`), or collapse many values to a summary (`summarise()`).

## New York City flight data

Let's apply these operations to a larger set of data. The data frame is in the package **nycflights13**. The data set is called `flights`. The notes follow closely from https://cran.rstudio.com/web/packages/dplyr/vignettes/introduction.html
```{r}
library(nycflights13)
dim(flights)
```

The data contains all 336,776 flights that departed NYC in 2013 and comes from the U.S. Bureau of Transporation Statistics. More information is available by typing `?nycflights13`.

The object flights is actually a tibble (tabled data frame). When you are dealing with a large data frame it is useful to make it a tibble so that you don't accidently print it to the screen.

For example, airquality is not a tibble. So when you type the name of the data frame the entire data frame scrolls in the console. To change a data frame to a tibble, use the function `tbl_df()`.
```{r}
airquality
airquality = tbl_df(airquality)
airquality
```

Returning to the NYC flights data.
```{r}
flights
```

The function `filter()` allows you to select a subset of rows in a data frame 

How would you extract all flights occurring on February 1st?
```{r}
flights %>%
  filter(month == 2 & day == 1)
```

The function `arrange()` works like `filter()` except that it reorders the rows. If you provide more than one column name, each additional column will be used to break ties in the values of the preceding columns.

How would you arrange all flights in descending order of departure delay?
```{r}
flights %>%
  arrange(desc(dep_delay))
```

Often you work with large datasets with many columns but only a few may be of interest. The function `select()` allows you to zoom in on an interesting subset of the columns.

How would you create a data frame containing only the dates, carrier, and flight numbers?
```{r}
df <- flights %>%
  select(year:day, carrier, flight)
df
```

You add new columns with the function `mutate()`.

Compute the time gained in flight by subtracting the departure delay (minutes) from the arrival delay.
```{r}
flights %>%
  mutate(gain = arr_delay - dep_delay) %>%
  select(year:day, carrier, flight, gain) %>%
  arrange(desc(gain))
```

Determine the mean departure delay.
```{r}
flights %>%
  summarize(avgDelay = mean(dep_delay, na.rm = TRUE))
```

### Randomly sample rows

You use `sample_n()` and `sample_frac()` to take random sample of rows from your data frame. Take a random sample of five rows from the flights data frame.
```{r}
flights %>%
  sample_n(5)
```

Take a random sample of 1% of the rows.
```{r}
flights %>%
  sample_frac(.01)
```

Use the argument `replace = TRUE` to perform a bootstrap sample. More on this later.

The verbs are powerful when you apply them to groups of observations within a data frame. This is done with the function `group_by()`. Determine the average arrival delay by airplane (tail number).
```{r}
flights %>%
  group_by(tailnum) %>%
  summarize(delayAvg = mean(arr_delay, na.rm = TRUE)) %>%
  arrange(desc(delayAvg))
```

Determine the number of distinct planes and flights by destination location.
```{r}
flights %>%
  group_by(dest) %>%
  summarize(planes = n_distinct(tailnum),
            flights = n())
```

Repeat but arrange from most to fewest planes.

## Tornado data

Let's review by using different data. The dataset was used to publish this recent [paper](http://myweb.fsu.edu/jelsner/PDF/Research/ElsnerEtAl2016.pdf). The data set through 2011 is available as a spreadsheet on my website.
```{r}
L = "http://myweb.fsu.edu/jelsner/temp/data/Tornadoes.txt"
Torn.df = read.table(L, header = TRUE)
dim(Torn.df)
head(Torn.df)
```

Each observation is a separate tornado. Variables include date, time, state, EF damage rating scale, fatalities, injuries, loss, start location, end location, length and width of path, and a few other things.

The start and end locations are given in decimal degrees of latitude and longitude. Missing locations are coded as 0.00. Path length is given in miles and path width is given in yards.

Reports are arranged chronologically starting with January 1950. The first tornado in the record is from January 3rd, 1950. It occurred in Missouri. 

There are quite a few tornadoes (56,221) so first make a tibble version of the data frame.
```{r}
Torn.df = tbl_df(Torn.df)
Torn.df
```

### Filter

Keep only tornadoes that occur in January.
```{r}
Torn.df %>%
  filter(MONTH == 1) %>%
  dim()
```

You read it as "Take the data frame `Torn.df` and filter it to remove all tornadoes except those occurring during the month of January."

You now have a filtered version of the original data frame consisting only of tornadoes occurring during the month of January. The function `dim()` on the filtered data frame or the function `length()` on one of the columns let's you know how many January tornadoes.

Multiple filtering conditions are joined together with a comma (or & for 'and').
```{r}
Torn.df %>%
  filter(MONTH == 1 & FSCALE >= 2)
```

The ampersand means 'and'. Filter by removing tornadoes except those occurring during January and with an damage rating of at least two.

You use the assignment statement to save the result of the filtering. The resulting object is a data frame and can be used by the function `ggplot()`.
```{r}
df <- Torn.df %>%
  filter(MONTH == 6 & DAY == 16)
```

Here the functions `ggplot()` and `geom_point()` plot the tornado latitude on the vertical (y) axis against year on the horizontal (x) axis for all tornadoes that have occurred on June 16th.
```{r}
library(ggplot2)
ggplot(df, aes(x = YEAR, y = SLAT)) + 
  geom_point() + 
  geom_smooth(method = lm)
```

The function `aes()` with `x = YEAR` and `y = SLAT` puts the year on the horizontal axis and latitude on the vertical axis. The function `geom_point()` places points on the graph. The function `geom_smooth()` with argument `method = lm` adds a straightline fit through the points with a 95% confidence band about the line.

The graph indicates that tornado activity is shifting northward over time. There is large variability from one year to the next and it is just one day of the year so no definitive conclusions should be drawn.

### Arrange and select

List the tornadoes in descending order of fatalities and injuries.
```{r}
Torn.df %>%
  arrange(desc(FATALITIES), desc(INJURIES)) %>%
  select(DATE, FATALITIES, INJURIES)
```

The first tie on fatalities occurs with 58. The tie is broken by the number of injuries.

### Mutate

Add a column that is the path area in square meters. Select only the date, EF rating, and columns corresponding to the path length, width and area.
```{r}
df <- Torn.df %>%
  mutate(Length = LENGTH * 1609,
         Width = WIDTH * .9144,
         Area = Length * Width * pi/4) %>%
  select(DATE, FSCALE, Length, Width, Area)
df
```

### Summarize

Compute the median tornado path length and width.
```{r}
df %>%
  summarize(mL = median(Length),
            mW = median(Width))
```

The median length is 805 meters and the median width is 37 meters.

### Commonalities

The functions `filter()`, `arrange()`, `select()`, `mutate()`, and `summarize()` have similar syntax. The first argument is always a data frame. Subsequent arguments describe what to do with it. You refer to columns in the data frame directly (without using `$`). The result is a new data frame. 

These properties make it easy to chain together multiple simple steps to achieve a complex result. These five functions provide the basis of a language of data manipulation.

At the most basic level, you can only alter a data frame in five useful ways: you can reorder the rows (arrange()), pick observations and variables of interest (filter() and select()), add new variables that are functions of existing variables (mutate()) or collapse many values to a summary (summarise()).

### Grouped operations

The verbs are useful, but they become powerful when you combine them with the idea of 'group by', repeating the operation individually on groups of observations within the dataset. 

You use the `group_by()` function to create a grouped object, which is a data frame divided by groups of rows. The verbs automatically work 'by group' when the input is a grouped object

In the following example, you group the data frame into `FSCALE` ratings and then count the number of tornadoes (`nT = n()`) and average the length (`mL = mean(Length)`) and width (`mW = mean(Width)`) for each group. Results are saved in a new data frame called `Paths`.
```{r}
Paths <- Torn.df %>%
  mutate(Length = LENGTH * 1609,
         Width = WIDTH * .9144) %>%
  group_by(FSCALE) %>%
  summarise(nT = n(),
            mL = mean(Length),
            mW = mean(Width))
Paths
```

Remove observations without an F scale rating of -99.
```{r}
Paths = Paths %>%
  filter(FSCALE >= 0)
ggplot(Paths, aes(x = factor(FSCALE), y = mL)) +
  geom_bar(stat = "identity")
```

We use `summarise()` with aggregate functions, which take a vector of values, and return a single number. There are many useful functions in base R like `min()`, `max()`, `mean()`, `sum()`, `sd()`, `median()`, and `IQR()`. Other include:

* `n()`: number of observations in the current group.
* `n_distinct(x)`: number of unique values in x.

For example, we could use these to find the number of tornadoes by state and the number of months in which there was at least one tornado.
```{r}
Torn.df %>%
  group_by(STATE) %>%
  summarize(months = n_distinct(MONTH),
            nT = n())
```

You can also group by multiple variables. For example how many tornadoes have occurred by day of year?
```{r}
Torn.df %>%
  group_by(MONTH, DAY) %>%
  summarize(nT = n())
```

This is what statisticians call exploratory data analysis, or EDA for short. EDA is an interative cycle. You:

1. Generate questions about your data.
2. Search for answers by transforming, visualizing, and modeling your data.
3. Use what you learn to refine your questions and/or ask new ones.

Your goal during EDA is to develop and understanding of your data. Use questions as tools to guide your investigation. When you ask a question, the question focuses your attention on a specific part of your dataset and helps you decide which transformations to make. For example:

On average what state has the longest tornadoes? Hint: `group_by()`, `summarize()`, `arrange()`.

Please check out http://r4ds.had.co.nz/index.html for additional help.
