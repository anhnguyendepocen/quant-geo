# Grammar for Graphs (1) {#GG1}

September 28, 2017

"**You're doing it right if you get frustrated: if you're not frustrated, you're (probably) not stretching yourself mentally.**"---Hadley Wickham

Problem Set #3 is due next Tuesday.

Today I'll start with a review of how to manipulate data using the verbs from the **dplyr** package. Then I'll elaborate on how to make graphs using functions from the **ggplot2** package. Graphs (and maps) are important to exploratory data analysis (EDA) in geography.

EDA is fundamentally a creative process. The key to asking good questions is to ask many of them. 

It's hard at first to ask good questions because you do not know what insights are contained in your dataset. But each new question exposes you to a new aspect of your data and increases your chance of making a discovery. You can quickly drill down into the most interesting parts of your data---and develop a set of thought-provoking questions---if you follow up each question with a new question based on what you find.

There is no rule about which questions you should ask to guide your research. However, two types will always be useful. Loosely worded these are:

* What type of variation occurs within my variables?
* What type of covariation occurs between my variables?

A variable is a quantity, quality, or property you can measure. A value is the state of a variable when you measure it. The value of a variable may change from measurement to measurement.

An observation is a set of measurements made under similar conditions (you usually make all of the measurements in an observation at the same time and on the same object). An observation will contain several values, each associated with a different variable. E.g., the observation of air temperatures at noon across Florida.

Tabular data is a set of values, each associated with a variable and an observation. Tabular data is 'tidy' if each value is placed in its own 'cell', each variable in its own column, and each observation in its own row.

## Data manipulation

Let's review what we learned on Tuesday by using the SPC tornado data. The dataset was used to publish this recent [paper](http://myweb.fsu.edu/jelsner/PDF/Research/ElsnerEtAl2016.pdf). The data set through 2011 is available as a spreadsheet on my website.
```{r}
L = "http://myweb.fsu.edu/jelsner/temp/data/Tornadoes.txt"
Torn.df = read.table(L, header = TRUE)
dim(Torn.df)
head(Torn.df)
```

Each observation is a separate tornado. Variables include date, time, state, EF damage rating scale (`FSCALE`), fatalities, injuries, loss, start location (`SLAT` and `SLON`), end location (`ELAT`, `ELON`), length (in miles) and width (in yards) of path, and a few other things. The start and end locations are given in decimal degrees of latitude and longitude. Missing locations are coded as 0.00. Reports are arranged chronologically starting with January 1950. The first tornado in the record is from January 3rd, 1950. It occurred in Missouri. 

Number two of Problem Set 3 asks some questions about these data.

There are many tornadoes (56,221) so we first make a tibble version of the data frame.
```{r}
library(dplyr)
Torn.df = tbl_df(Torn.df)
Torn.df
```

### Filter

Keep only tornadoes that occurred during the month of January.
```{r}
Torn.df %>%
  filter(MONTH == 1) %>%
  dim()
```

We now have a filtered version of the original data frame consisting only of tornadoes occurring during January. The function `dim()` on the filtered data frame or the function `length()` on one of the columns let's us know how many January tornadoes are in the dataset.

Multiple filtering conditions are joined together with a comma (or & for 'and').
```{r}
Torn.df %>%
  filter(MONTH == 1 & FSCALE >= 2)
```

The ampersand means 'and'. Keep only tornadoes occurring during January AND with an damage rating of at least two.

We can use the assignment statement to save the result of the filtering. Or we can send ('pipe') the resulting object to `ggplot()`. For example: Here the functions `ggplot()` and `geom_point()` plot the tornado latitude on the vertical (y) axis against year on the horizontal (x) axis for all tornadoes that have occurred on June 16th.
```{r}
library(ggplot2)
Torn.df %>%
  filter(MONTH == 6 & DAY == 16) %>%
ggplot(., aes(x = YEAR, y = SLAT)) + 
  geom_point() + 
  geom_smooth(method = lm)
```

The function `aes()` with `x = YEAR` and `y = SLAT` puts the year on the horizontal axis and latitude on the vertical axis. The function `geom_point()` places points on the graph. The function `geom_smooth()` with argument `method = lm` adds a straightline fit through the points with a 95% uncertainty band about the line.

The graph indicates that tornado activity is shifting northward over time. There is large variability from one year to the next and it is just one day of the year so no definitive conclusions can be drawn.

### Arrange and select

List the tornadoes in descending order of fatalities and injuries.
```{r}
Torn.df %>%
  arrange(desc(FATALITIES), desc(INJURIES)) %>%
  select(DATE, FATALITIES, INJURIES)
```

The first tie on fatalities occurs with 58. The tie is broken by the number of injuries. Note that the operations are commutative. We could have selected then arranged and the results would have been the same.

### Mutate

Add a column that gives the path area in square meters where the area is computed using the formula for an ellipse. Select only the date, EF rating, and columns corresponding to the path length, width and area.
```{r}
df = Torn.df %>%
  mutate(Length = LENGTH * 1609,
         Width = WIDTH * .9144,
         Area = Length * Width * pi/4) %>%
  select(DATE, FSCALE, Length, Width, Area)
df
```

In this case the order is important.

### Summarize

Compute the median tornado path length and width.
```{r}
df %>%
  summarize(mL = median(Length),
            mW = median(Width))
```

The median path length is 805 meters and the median (max) path width is 37 meters.

The functions `filter()`, `arrange()`, `select()`, `mutate()`, and `summarize()` have similar syntax. The first argument is always a data frame. Subsequent arguments describe what to do with it. You refer to columns in the data frame directly (without using `$`). The result is a new data frame. These properties make it easy to chain together multiple simple steps to achieve a complex result. These five functions provide the basis of a language of data manipulation.

### Grouped operations

We use the `group_by()` function to create a grouped object, which is a data frame divided by groups of rows. The verbs work 'by group' when the input is a grouped object

In the following example, we group the data frame into `FSCALE` ratings and then count the number of tornadoes (`nT = n()`) and average the length (`mL = mean(Length)`) and width (`mW = mean(Width)`) for each group. Results are saved in a new data frame called `Paths`.
```{r}
Paths = Torn.df %>%
  mutate(Length = LENGTH * 1609,
         Width = WIDTH * .9144) %>%
  group_by(FSCALE) %>%
  summarise(nT = n(),
            mL = mean(Length),
            mW = mean(Width))
Paths
```

Here we assign (save) the result in `Paths`. Next we remove observations without an F scale rating of -99 and create a bar plot.
```{r}
Paths = Paths %>%
  filter(FSCALE >= 0)
ggplot(Paths, aes(x = factor(FSCALE), y = mL)) +
  geom_bar(stat = "identity")
```

You use `summarise()` with aggregate functions, which take a vector of values, and return a single number. For example, we find the number of tornadoes by state and the number of months in which there was at least one tornado.
```{r}
Torn.df %>%
  group_by(STATE) %>%
  summarize(months = n_distinct(MONTH),
            nT = n())
```

We can also group by multiple variables. For example how many tornadoes have occurred by day of year?
```{r}
Torn.df %>%
  group_by(MONTH, DAY) %>%
  summarize(nT = n())
```

EDA is an interative cycle. You:

1. Generate questions about your data.
2. Search for answers by transforming, visualizing, and modeling your data.
3. Use what you learn to refine your questions and/or ask new ones.

Your goal is to develop an understanding of your data. Use questions as tools to guide your investigation. When you ask a question, the question focuses your attention on a specific part of your dataset and helps you decide which transformations to make. For example: On average what state has the longest tornadoes? Hint: `group_by()`, `summarize()`, `arrange()`.

```{r}
Torn.df %>%
  group_by(STATE) %>%
  summarize(mL = mean(LENGTH)) %>%
  arrange(desc(mL))
```

For additional practice please check out http://r4ds.had.co.nz/index.html.

## Grammer for graphs

The **ggplot2** package has functions for making nice graphs easily. The 'gg' stands for the 'Grammar of Graphics,' a theory of how to create a graphics system from Leland Wilkinson.

The grammar specifies how a plot translates data to attributes of geometric objects. Attributes are things like color, shape, and size and the geometric objects are things like points, lines, bars, and polygons.

A plot is drawn using a coordinate system and it may contain manipulations of the data. Faceting replicates the plot using subsets of the data (like 'group by').

The plot type depends on the geometric object, which is specified as a function. The function name begins with `geom_`. For example, to create a histogram the `geom_histogram()` function is used.

Load the **ggplot2** package.
```{r}
library(ggplot2)
```

Pro tip: make sure you have a call to the package load function (`library()`) in your code before you knit.

http://r4ds.had.co.nz/exploratory-data-analysis.html

### Bar chart

Read the hurricane data from the file on my website and list the first six rows.
```{r}
L = "http://myweb.fsu.edu/jelsner/temp/data/US.txt"
H = read.table(L, header = TRUE)
head(H)
```

The function `table()` creates a frequency table of the landfall counts.
```{r}
table(H$All)
```

The number of cases for each count is tallied and displayed below the count. There were 36 cases of 0 hurricanes. Each case is a year.

The function `geom_bar()` creates a bar chart of this frequency table.
```{r}
ggplot(H, aes(x = All)) + 
  geom_bar()
```

The first function is `ggplot()`. It takes as it's first argument the name of the data frame (`H`). The second argument is the function `aes()` that indicates what variables to use in the plot. With `x = All` the variable `All` from the data frame `H` is identified as the variable to plot.

The plotting is done by mapping some characteristic of the variable to a visual property. This mapping is done with the second function `geom_bar()`. The function `geom_bar()` tables the counts and then maps the number of cases to bars with the bar height proportional to the number of cases. Here the number of cases is the number of years with that many hurricanes.

The functions are applied in order (`ggplot()` comes before `geom_bar()`) and are linked with the addition `+` symbol. In this way we can think of the functions as layers in a GIS.

The bar chart contains the same information as displayed by the function `table()`. The y-axis label is 'count' and x-axis label is the column name. 

Repeat this time using Florida hurricane counts. The annual number of Florida hurricanes by year is given in column `FL` in the data frame `H`.
```{r}
H$FL
```

The `geom_bar()` function tables these numbers and plots the frequency as a bar.
```{r}
ggplot(H, aes(x = FL)) + 
  geom_bar() +
  xlab("Number of Florida Hurricanes (1851-2016)") +
  ylab("Number of Years")
```

Here axes labels are placed on the plot with the functions `ylab()` and `xlab()`. With this type of 'layering' it's easy to go from data on the web to a publishable plot.

### Beer preference

Thirty graduate students are surveyed about their beer drinking preferences. Categories are (1) domestic can, (2) domestic bottle, (3) microbrew, and (4) import. To make a bar chart first create the data as a character vector and then change the vector to a data frame.
```{r}
beer = c(rep('domestic bottle', 4), 
         rep('domestic can', 12), 
         rep('import', 5), 
         rep('microbrew', 9))
beerPref.df = as.data.frame(beer)
```

Use the function `str()` to see the column types in the data frame.
```{r}
str(beerPref.df)
```

There is one column in the data frame with the name `beer`. It is a factor with 4 levels one for each type of beer choice. A factor is a categorical vector. It looks like a character but it can be ordered. This is important when factors are used in statistical models.

Create a table.
```{r}
table(beerPref.df$beer)
```

Create a bar chart and specify the axis labels.
```{r}
ggplot(beerPref.df, aes(beer)) + 
  geom_bar() +
  xlab("Beer Preference") + 
  ylab("Number of Students")
```

This is a good start but a few improvements should be made.

1. The bar order is alphabetical from left to right. This is the default ordering for factors created from character vectors. It is much easier to make comparisons if frequency determines the order.

To change the order on the bar chart specify the factor levels on the vector beer.
```{r}
beer = factor(beer, levels = c("domestic can", "microbrew", "import", "domestic bottle"))
beerPref.df = data.frame(beer)
```

Now remake the bar chart.
```{r}
ggplot(beerPref.df, aes(beer)) + 
  geom_bar() +
  xlab("Beer Preference") + 
  ylab("Number of Students")
```

2. The vertical axis tic labels are fractions. Since the bar heights are counts (integers) the tic labels also should be integers.

To override this default you add a new y-axis layer. The layer is the function `ylim()` where you indicate the lower and upper limits of the axis with the concatenate (`c()`) function. Now remake the bar chart.
```{r}
ggplot(beerPref.df, aes(beer)) + 
  geom_bar() +
  xlab("Beer Preference") + 
  ylab("Number of Students") +
  ylim(c(0, 15))
```

Now the chart is publishable and this schema works for print media. Options exist for changing the look of the plot for digital media include, colors, orientation, background, etc.

For example to change the bar color use the `fill =` argument in the function `geom_bar()`. To change the orientation of the bars use the layer function `coord_flip`, and to change the background use the layer function `theme_minimal()`

You can make changes to the look of the plot with additional layers.
```{r}
ggplot(beerPref.df, aes(beer)) + 
  geom_bar(fill = "orange2") +
  xlab("Beer Preference") + 
  ylab("Number of Students") +
  ylim(c(0, 15)) +
  coord_flip() +
  theme_minimal()
```

Note that the `fill =` is used on the variable given in the `aes()` function.

The available colors include 
```{r eval=FALSE}
colors()
```

It is a bit more complicated to automatically change the bar order based on frequency. Here is an example for storm intensity of tropical cyclones thus far in 2017.
```{r}
minP = c(990, 1007, 992, 1007, 1005, 981, 967, 938, 914, 938, 972, 971)
name = c("Arlene", "Bret", "Cindy", "Don", "Emily", "Franklin", "Gert", 
         "Harvey", "Irma", "Jose", "Katia", "Lee")

df = data.frame(name, minP) %>%
  mutate(name = reorder(name, minP))

ggplot(df, aes(x = name, y = minP, fill = minP)) + 
  geom_bar(stat = "identity") +
  xlab("Storm Name") + 
  ylab("Minimum Sea Level Pressure [mb]") 
```

The key is the function `reorder()`, which treats its first argument as a categorical factor variable and reorders the levels of this factor based on the values of the variable in the second argument.

### Histogram

The histogram is similar to the bar chart except the histogram uses bars to indicate frequency (or proportion) over an interval of continuous values. For instance, with continuous values the function `table()` is not useful.
```{r}
x = rnorm(10)
table(x)
```

So neither is a bar plot.

A histogram is made as follows: First a contiguous collection of disjoint intervals, called bins, covering the range of data points is chosen.  "Disjoint" means no overlap, so the intervals look like (a,b] or [a,b). The interval (a,b] means the interval contains all the values from a to b including b but not a, whereas the interval [a,b) means the interval contains all the values from a to b including a but not b.

Second, the number of data values in each of these intervals is counted.  Third, a bar is drawn above the interval so that the area of the bar is proportional to the frequency. If the intervals defining the bins have the same width, then the height of the bar is proportional to the frequency (the number of values inside the interval).

Let's return to the Florida precipitation data.
```{r}
L = "http://myweb.fsu.edu/jelsner/temp/data/FLprecip.txt"
FLp = read.table(L, na.string = "-9.900", 
                 header = TRUE)
str(FLp)
```

Columns in the data frame `FLp` are months (variables) and rows are years. `Year` is an integer (int) vector and the months are numeric (num) vectors. Create a histogram of May precipitation.
```{r}
ggplot(FLp, aes(May)) + 
  geom_histogram()  +
  xlab("May Precipitation in Florida (in)") 
```

By default the function `geom_histogram()` picks 30 bins. Since there are only 118 May values many of the bins have fewer than 5 values.

When making a histogram you will almost certainly need to vary the number of bins before deciding on a final plot. This can be done with the `bins =` or `binwidth =` argument. For example, the look of the histogram is improved by halving the default number of bins.
```{r}
ggplot(FLp, aes(May)) + 
  geom_histogram(bins = 15)  +
  xlab("May Precipitation in Florida (in)") 
```

It looks even better by decreasing the number of bins to 11.
```{r}
ggplot(FLp, aes(May)) + 
  geom_histogram(bins = 11, fill = "green")  +
  xlab("May Precipitation in Florida (in)") +
  ylab("Number of Years")
```

Here the fill argument is used to change color and a `ylab()` layer is added to make the y-axis label more concise.

The `geom_rug()` layer adds the location of the data values as tic marks just above the horizontal axis.
```{r}
ggplot(FLp, aes(May)) + 
  geom_histogram(bins = 11, fill = "green")  +
  xlab("May Precipitation in Florida (in)") +
  ylab("Number of Years") +
  geom_rug()
```

### Density plot

A density plot is a smoothed histogram with units of probability on the vertical axis. It's motivated by the fact that for a continuous variable, the probability that X takes on any particular value x is 0 so we need a range of values over which we can define a probability.

The probability density answers the question, what is the probability that X falls in a small interval. This probability varies depending on where X is located (e.g., near the middle of the distribution or near the tails).
```{r}
ggplot(FLp, aes(May)) +
  geom_density() +
  xlab("May Precipitation in Florida (in)")
```

The probability axis (vertical) is the integral (average) chance that rainfall will take on a value along the horizontal axis within a given small interval. The size of the interval is determined by the bandwidth (`bw =`).
```{r}
ggplot(FLp, aes(May)) +
  geom_density(bw = 1) +
  xlab("May Precipitation in Florida (in)")
```

The probability scale depends on the data units so it is often tricky to intepret. Instead `geom_freqpoly()` produces a density-like graph where the units on the y-axis are counts as with the histogram.
```{r}
ggplot(FLp, aes(May)) + 
  geom_freqpoly(color = "green3", binwidth = 1) +
  xlab("May Precipitation in Florida (in)") +
  geom_rug()
```

### Box plot

The box plot graphs five summary statistics including the min, max, 1st & 3rd quartiles, and the median. The easiest way to create a box plot is to use the function `boxplot()`.
```{r}
boxplot(FLp$May)
```

The function `boxplot()` is from the base **graphics** package. Others from this package include `hist()` for histograms and `plot()` for scatter plots. 

The base graphics lets you manipulate every detail of a graph, which is great for customization. For example:
```{r}
boxplot(FLp$May, 
        ylab = "May Precipitation in FL (in)")
f = fivenum(FLp$May)
text(rep(1.3, 5), f, labels = c("Minimum", "1st Quartile", 
                                "Median", "3rd Quartile",
                                "Maximum"))
text(1.3, 7.792, labels = "Last Value Within\n 1.5xIQR Above 3rd Q")
```

The box plot illustrates the five numbers graphically. The median is the line through the box. The bottom and top of the box are the 1st and 3rd quartile values. Whiskers extend vertically from the box downward toward the minimum and upward toward the maximum. 

If values extend beyond 1.5 times the interquartile range (either above or below the corresponding quartile) the whisker is truncated at the last value within the range and points are used to indicate outliers.

To make a box plot using the function `ggplot()` you need a dummy variable for the `x` argument in the function `aes()`. This is done with `x = ""`.
```{r}
ggplot(FLp, aes(x = "", y = May)) + 
  geom_boxplot() +
  xlab("") + 
  ylab("May Precipitation in Florida (in)")
```

### Side-by-side box plots

Suppose you want to show box plots for each month. In this case you make the x argument in the `aes()` the name of a column containing the vector of month names. Since the data frame is in a wide format, you need to reshape it.

You do this with the function `melt()` from the **reshape2** package.
```{r}
library(reshape2)
head(FLp)
FLpL = melt(FLp, id.vars = "Year")
head(FLpL)
```

The `melt()` function takes all the values as measured. All variables are measured (precipitation in units of inches) except `Year`. `Year` is a vector identifying the year so it is specified as an `id.vars` as a argument.

The long data frame lists the measured variable names as the first column. The variable names are the names of the columns in the original data frame starting with `Jan`. The long data frame list the values in the third column.

To create the box plot specify that the x-axis be the variable.
```{r}
ggplot(FLpL, aes(x = variable, y = value)) + 
  geom_boxplot() +
  xlab("Month") + 
  ylab("Precipitation (in)")
```

This is a climograph.

Each `geom_` function is a layer. Data for the layer is specified in the function `ggplot()` with the data frame argument and the `aes()` function. To add another layer to the plot with different data you specify the data within the geom function. For example, lets repeat the climograph of monthly precipitation highlighting the month of May.

We add another `geom_boxplot()` layer and specify a subset of the data using the subset `[]` operator.
```{r}
ggplot(FLpL, aes(x = variable, y = value)) + 
  geom_boxplot() +
  xlab("Month") + 
  ylab("Precipitation (in)") +
  geom_boxplot(data = FLpL[FLpL$variable == "May", ], 
               aes(x = variable, y = value), 
               fill = "green")
```

Practice: Make a climograph from the monthly SOI data. Here I put the functions in the proper order but I left out some details.
```{r eval=FALSE}
L = "http://myweb.fsu.edu/jelsner/temp/data/SOI.txt"
SOI = read.table(file = , header = TRUE)
SOIL = melt(SOI, id.vars = )
ggplot(SOIL, aes(x =  , y = )) + 
  geom_boxplot() +
  xlab("Month") + 
  ylab("SOI (s.d.)")
```

### Scatter plot

The work horse of statistical graphs is the scatter plot. It's a graph of the values of one variable against the values of the other as points $(x_i, y_i)$ in a Cartesian plane. It's used to show the relationship between two numeric variables. 

For example, to show the relationship between April and September values of Florida precipitation type
```{r}
ggplot(FLp, aes(x = Apr, y = Sep)) + 
  geom_point() + 
  xlab("April Precip. (in)") + 
  ylab("September Precip. (in)")
```

The plot shows that dry Aprils tend to be followed by dry Septembers and wet Aprils tend to be followed by wet Septembers. You observe there is a direct (or positive) relationship between the two variables although the points are scattered widely indicating the relationship is weak.

If your goal is to model the relationship, you plot the dependent variable (the variable you are interested in modeling) on the vertical axis. Here you put the September values on the vertical axis since a predictive model would use April values to forecast September values.

If the points have a natural ordering then you use the `geom_line()` function. For example, to plot the September precipitation values as a time series type
```{r}
ggplot(FLp, aes(x = Year, y = Sep)) + 
  geom_line() + 
  xlab("Year") + 
  ylab("September Precip. (in)")
```

Precipitation values fluctuate from one September to the next, but there does not appear to be a long-term trend. With time series data it is better to connect the values with lines rather than use points unless values are missing.

Practice: Create a plot of the May values of the North Atlantic oscillation (NAO) with Year on the horizontal axis. Add appropriate axis labels.
```{r eval=FALSE}
L = "http://myweb.fsu.edu/jelsner/temp/data/NAO.txt"
NAO = read.table(file = L, header = TRUE)
ggplot(NAO, aes(x = Year, y = May)) + 
  geom_line() + 
  xlab("Year") + 
  ylab("North Atlantic Oscillation (s.d.)")
```

### Create a plot object

The assignment operator can be used to save the plot as an object. The object can be modified and printed.

Example: Given the 'cars' data frame from the **datasets** package. 
```{r}
str(cars)
```

Plot the car's stopping distance (`dist`) on the vertical (y) axis and the car's forward speed (`speed`) on the horizontal axis (x). Create the plot but assign it to an object called `p`.
```{r}
p = ggplot(cars, aes(x = speed, y = dist)) +
        geom_point() +
        xlab("Forward Speed (mph)") +
        ylab("Stopping Distance (ft)")
p
p = p + theme_bw()
p
p + geom_rug()
```

Notes:

1. the `aes()` function creates a list of variables to map. Here speed and dist from the data frame cars. The default argument list is ordered with the x variable first then the y variable, but it is good coding practice to name them using `x =` , etc.
2. The first layer is `geom_point()`. It maps the aesthetics to a cartesian plane. The `geom_point()` function needs an x and y aesthetic, but also understands `color`, `fill`, `shape`, `size`, `alpha`.
3. The second and third layers add labels to the axes. 
4. The graph is first saved as an object called `p` rather than rendered by the graphical device. It gets rendered by typing its name.
5. Additional layers are added to `p` using the `+` symbol.

The ggplot object `p` is a list of length 9 elements. Type
```{r, eval=FALSE}
str(p)
```

The first element is the data frame. The last element are the labels.

### Export a graph

When you knit to HTML and a plot is produced it gets output as a png file in a folder called "figure" in the directory where your .Rmd file is located.

You can also use the Export button under the Plots tab.

Or you can export the file directly using R code. Here the file gets put into your working directory.
```{r eval = FALSE, dev=c("pdf", "png")}
png(file = "MayNAO.png")
ggplot(NAO, aes(x = Year, y = May)) + 
  geom_line() + 
  xlab("Year") + 
  ylab("May NAO (s.d.)")
dev.off()
```

Note that the function `png()` opens the device and the function `dev.off()` closes it.  

Recall to list the files in your working directory type `dir()`.

My workflow. 

### Give it a try

Use the `cars` data frame (**datasets**) to create a histogram and box plot of stopping distance (column name `dist`). Also create a scatter plot of stopping distance (`dist`) versus `speed` with `speed` on the horizontal axis.

## Problem Set # 3

Due Date: October 3, 2017
Total Points: 45

**1** The dataset *hflights* from the **hflights** package contains all 227,496 flights that departed Houston in 2011. Using the functions in the **dplyr** package

a. Create a new data frame from *hflights* containing only those flights that departed on September 11th of that year. (5)

b. How many flights departed on that day? (5)

c. Create a data frame with the first column being the tail number and the second being the number of departures from Houston the plane made that year sorted by most to least number of flights. (5)

**2** Answer the following questions using the tornado data set (http://myweb.fsu.edu/jelsner/temp/data/Tornadoes.txt).

a. Use the functions `group_by()` and `summarize()` to determine the number of tornadoes by each state. (5)

b. Create a new column with path length in meters (`LENGTH` is is miles). Create a new data frame by removing rows with EF damage rating below 3. Group by year and summarize the average path length. Make a graph with year on the x axis and average path length on the y axis. (10)

c. Compute the number of tornadoes with EF damage rating 1 or higher by year and graph the results as a time series (year on the horizontal axis). (10)

d. Create a data frame with the year in the first column and the total number of tornadoes in Kansas by year in the second column. List the first six rows of this new data frame. (5)